---
style: |
  img {
    display: block;
    float: none;
    margin-left: auto;
    margin-right: auto;
  }
marp: true
paginate: true
---
# chatbot.py

---
## [python-dotenv](https://daco2020.tistory.com/480)
- Pythonì—ì„œëŠ” python-dotenv ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ë³€ìˆ˜ë¥¼ ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.

---
### ë‹¨ê³„1: ì„¤ì¹˜
```shell
pip install python-dotenv
```
### ë‹¨ê³„2: `.env`
- `.env` íŒŒì¼ì— í™˜ê²½ë³€ìˆ˜ ì„¤ì • 
```shell
USER_NAME="í™ê¸¸ë™"
```

---
### ë‹¨ê³„3: ì‚¬ìš©ë²•
```python
import os
from dotenv import load_dotenv

# .envì— ë“±ë¡ëœ ë°ì´í„°ë¥¼ os í™˜ê²½ë³€ìˆ˜ì— ì ìš©
load_dotenv()

# os í™˜ê²½ë³€ìˆ˜ì— ë“±ë¡ëœ ë°ì´í„° í™•ì¸ 
SECRET_ENV = os.getenv("SECRET_ENV")
```

---
## [streamlit chatbot](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps) 
- streamlitì„ ì´ìš©í•˜ì—¬ chatbot êµ¬ì¶• 

### ë‹¨ê³„1: ì„¤ì¹˜
```shell
pip install streamlit
```
---
### ë‹¨ê³„2: chat_input
- ì‚¬ìš©ìê°€ chatì„ ì…ë ¥í•˜ëŠ” widget
```python
import streamlit as st

prompt = st.chat_input("Say something")
if prompt:
    st.write(f"User has sent the following prompt: {prompt}")
```

---
### ë‹¨ê³„3: chat_message
- ì‚¬ìš©ìì˜ chatê³¼ ì‘ë‹µì„ ë³´ì—¬ì¤Œ
```python
import streamlit as st

with st.chat_message("user"):
    st.write("Hello ğŸ‘‹")
```

---
### ë‹¨ê³„4: session_state 
- chat historyë¥¼ ì €ì¥
```python
import streamlit as st

st.title("Echo Bot")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
```

---
### ë‹¨ê³„5: ì‹¤í–‰
```shell
streamlit run chatbot.py
```
![bg right w:600](image-1.png)

---
# [chatbot_with_openai.py](https://platform.openai.com/docs/api-reference/chat)

---
### ë‹¨ê³„1: ì„¤ì¹˜
```shell
pip install openai
```
### ë‹¨ê³„2: `.env`
- `.env` íŒŒì¼ì— í™˜ê²½ë³€ìˆ˜ ì„¤ì • 
```shell
OPENAI_API_KEY="openai api key ì…ë ¥"
```

---
### [ë‹¨ê³„3: Caching by Streamlit](https://docs.streamlit.io/develop/concepts/architecture/caching#caching-overview) 
- ìºì‹±ì€ ë°ì´í„°ë¥¼ ì¼ì‹œì ìœ¼ë¡œ ê³ ì† ë°ì´í„° ì €ì¥ ê³„ì¸µì¸ ìºì‹œì— ì €ì¥í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. 
- ìºì‹±ì˜ ì£¼ìš” ëª©ì ì€ ê¸°ì¡´ì˜ ëŠë¦° ì €ì¥ ê³„ì¸µì— ì ‘ê·¼í•  í•„ìš” ì—†ì´ ë°ì´í„° ê²€ìƒ‰ ì†ë„ë¥¼ ë†’ì´ëŠ” ë° ìˆìŠµë‹ˆë‹¤. 
- ë°ì´í„°ê°€ ìš”ì²­ë˜ë©´ ì‹œìŠ¤í…œì€ ë¨¼ì € ìºì‹œë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ ë°œê²¬ë˜ë©´ ì¦‰ì‹œ ë°˜í™˜ë©ë‹ˆë‹¤. 
- ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œì€ ë°ì´í„°ë¥¼ ì›ë˜ ì €ì¥ì†Œì—ì„œ ê°€ì ¸ì˜¤ê³  ë°˜í™˜í•œ í›„ ë¯¸ë˜ì˜ ìš”ì²­ì„ ìœ„í•´ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤.

---
#### Streamlit Cache ì¥ì 
- `ì„±ëŠ¥ í–¥ìƒ`: ìºì‹œì— ë¹„ì‹¼ í•¨ìˆ˜ í˜¸ì¶œ ê²°ê³¼ë¥¼ ì €ì¥í•¨ìœ¼ë¡œì¨ Streamlit ì•±ì˜ ì†ë„ë¥¼ ëŒ€í­ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì´ë‚˜ ë³µì¡í•œ ê¸°ê³„ í•™ìŠµ ëª¨ë¸ê³¼ í•¨ê»˜ ì‘ì—…í•  ë•Œ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ê³„ì‚°ì— ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ëŠ” ê²½ìš°ì— ì´ì ì´ í½ë‹ˆë‹¤.
- `íš¨ìœ¨ì„± ì¦ëŒ€`: ìºì‹±ì„ í†µí•´ ë¶ˆí•„ìš”í•œ ê³„ì‚°ì„ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•¨ìˆ˜ê°€ ì´ì „ê³¼ ê°™ì€ ì¸ìˆ˜ë¡œ ì´ì „ì— í˜¸ì¶œëœ ê²½ìš°, Streamlitì€ í•¨ìˆ˜ì˜ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•˜ëŠ” ëŒ€ì‹  ìºì‹œì—ì„œ ê²°ê³¼ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- `ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ`: ë¡œë“œ ì‹œê°„ì´ ë” ë¹ ë¥´ê³  ë°˜ì‘ì„±ì´ ë†’ì€ ì•±ì€ ë” ì¢‹ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ìºì‹±ì„ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ìëŠ” ì•±ê³¼ ìƒí˜¸ì‘ìš©í•  ë•Œë§ˆë‹¤ ë°ì´í„°ê°€ ë¡œë“œë˜ê±°ë‚˜ ê³„ì‚°ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.

---
#### st.cache_data
```python
@st.cache_data  # ğŸ‘ˆ Add the caching decorator
def load_data(url):
    df = pd.read_csv(url)
    return df

df = load_data("https://github.com/plotly/datasets/raw/master/uber-rides-data1.csv")
st.dataframe(df)

st.button("Rerun")
```

---
#### st.cache_resource
```python
from transformers import pipeline

@st.cache_resource  # ğŸ‘ˆ Add the caching decorator
def load_model():
    return pipeline("sentiment-analysis")

model = load_model()

query = st.text_input("Your query", value="I love Streamlit! ğŸˆ")
if query:
    result = model(query)[0]  # ğŸ‘ˆ Classify the query text
    st.write(result)
```

---
### ë‹¨ê³„4: OpenAI Chat ìƒì„±
```python
import streamlit as st
from openai import OpenAI

@st.cache_resource
def get_client_of_openai():
    return OpenAI()

client = get_client_of_openai()

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Say this is a test"}],
    stream=True,
)
for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

---
### ë‹¨ê³„5: ì‹¤í–‰ 
```shell
streamlit run chatbot_with_openai.py
```
![bg right w:600](image.png)

---
# [chatbot_with_rag.py](https://github.com/cailynyongyong/solar-llm/blob/master/chatbot.py)
- https://alphalog.co.kr/227
- https://gniogolb.tistory.com/17
- https://wikidocs.net/230759

---
## Install Chroma Vector DB
- [Install Chroma on Window ì—ëŸ¬](https://stackoverflow.com/questions/73969269/error-could-not-build-wheels-for-hnswlib-which-is-required-to-install-pyprojec/76245995#76245995)

---
### [ë‹¨ê³„1: Microsoft C++ Build Tools ë‹¤ìš´ë¡œë“œ](https://visualstudio.microsoft.com/ko/visual-cpp-build-tools/)
![alt text](image-2.png)

---
### ë‹¨ê³„2: Microsoft C++ Build Tools ì‹¤í–‰ ë° ì„¤ì¹˜
![alt text](image-3.png)

---
### ë‹¨ê³„3: install Chroma 
```shell
pip install chromadb langchain-chroma
```
![alt text](image-5.png)

---
## RAG(Retrieval-Augmented Generation)
![alt text](image-4.png)

---



