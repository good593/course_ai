question,contexts,ground_truth,evolution_type,metadata,episode_done
What is the significance of making AI forget about copyrighted material?,"[',\n학계, 시민사회 및 일반 대중과 정보 공유 채널을 구축\n∙ AI 안전성 정상회의(AI Safety Summit)에서 합의된 대로 첨단 AI 모델의 평가 후 해당 모델이 배포된\n타국의 정부 및 연구소와 평가 결과를 공유하고, 학계와 대중이 AI 시스템의 피해와 취약점을 보고할 수\n있는 명확한 절차를 수립\n☞ 출처 : Gov.uk, Introducing the AI Safety Institute, 2023.11.02.\nVenturebeat, Researchers turn to Harry Potter to make AI forget about copyrighted material, 2023.10.06.\n']",The answer to given question is not present in context,simple,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 17, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
What is the significance of LLM in the context of RAG and its applications?,"['포함한 질문과 답변 △RAG\n없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을\n기준으로 LLM의 순위를 평가\n* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\nn 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도\nGPT-4와 거의 동등한 성능을 발휘\n∙ 메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴\n형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅\n페이스의 제퍼(Zephyr-7b)가 라마2를 능가\n<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\n☞ 출처: Galileo, LLM Hallucination Index, 2023.11.15.\n']","The significance of LLM in the context of RAG (Retrieval-Augmented Generation) lies in its ability to enhance the performance of AI models like GPT-4 and GPT-3.5 by integrating external information retrieval mechanisms. This allows for improved accuracy and relevance in generating responses, as LLMs can access and utilize up-to-date information from various sources, thereby addressing issues related to hallucinations and providing more reliable outputs.",simple,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 19, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
"What specific types of AI policy recommendations, such as ethical guidelines or regulatory frameworks, were discussed at the AI Safety Summit in November 2023?","['SPRi AI Brief |\n2023-12월호\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\nKEY Contents\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\n채택을 권고하는 AI 국제 행동강령을 마련\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\n위험 식별과 완화에 필요한 조치를 포함\n* 주요 7개국(G7)은 미국, 일본, 독일, 영', '1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\nKEY Contents\nn 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을\n위한 협력 방안을 담은 블레츨리 선언을 발표\nn 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며,\n영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정\n£AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\nn 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에\n참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표\n∙ 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이\n중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여\nAI 시스템의 안전을 보장할 책임이 있다고']",The answer to given question is not present in context,simple,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
What are the performance metrics used to evaluate AGI?,"['�요\n∙ (범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\n∙ (인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과\n메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\n∙ (실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행\n∙ (생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로\n가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\n∙ (종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정\nn 연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정\n과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현', '구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\nKEY Contents\nn 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을\n0~5단계까지 총 6단계로 구분한 프레임워크를 공개\nn 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만\n광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음\n£챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\nn 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와\n성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n∙ 프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI\n달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\nn 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\n∙ (프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 �']",The answer to given question is not present in context,simple,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
What can we learn about data transparency from Cohere's Explorer?,"[' 법적 프레임\n워크의 필요성을 제기\n∙ 일례로 데이터를 수집한 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을\n적용해야 하는지 실무자의 판단이 어려울 수 있으며, 서로 다른 라이선스를 적용받는 개별 데이터셋을\n하나로 통합해 사용하는 경우에도 각각의 라이선스 조건 준수에 어려움이 발생\n☞ 출처 : Cohere, Data Provenance Explorer Launches to Tackle Data Transparency Crisis, 2023.10.25.\n8\n']",The answer to given question is not present in context,reasoning,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 10, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
"What were the main goals of the AI Safety Summit on Nov 2, 2023?","['�으로 함\nn (첨단 AI 시스템 평가 개발과 시행) 시스템의 안전 관련 속성을 중심으로 안전과 보안 기능을 이해\n하고 사회적 영향을 평가\n∙ 평가 우선순위는 △사이버범죄 조장, 허위 정보 유포 등 악의적으로 활용될 수 있는 기능 △사회에 미치는\n영향 △시스템 안전과 보안 △인간의 통제력 상실 가능성 순\n∙ 연구소는 외부 기관과 협력해 자체 시스템 평가를 개발 및 수행하고, 평가와 관련된 의견 공유 및 지침\n마련을 위해 전문가 커뮤니티를 소집할 계획\nn (AI 안전 연구 촉진) 외부 연구자를 소집하고 다양한 예비 연구 프로젝트를 통해 AI 안전 기초연구를 수행\n∙ AI 시스템의 효과적 거버넌스를 위한 도구 개발* 및 안전한 AI 시스템 개발을 위한 새로운 접근 방식 연구를 수행\n* 편향된 훈련 데이터에 대한 분석기술, 민감한 정보를 포함하는 AI 시스템에 대한 미세 조정 방법\nn (정보 교류 활성화) 현행 개인정보보호와 데이터 규제 하에서 연구소와 정책입안자, 국제 파트너', ',\n학계, 시민사회 및 일반 대중과 정보 공유 채널을 구축\n∙ AI 안전성 정상회의(AI Safety Summit)에서 합의된 대로 첨단 AI 모델의 평가 후 해당 모델이 배포된\n타국의 정부 및 연구소와 평가 결과를 공유하고, 학계와 대중이 AI 시스템의 피해와 취약점을 보고할 수\n있는 명확한 절차를 수립\n☞ 출처 : Gov.uk, Introducing the AI Safety Institute, 2023.11.02.\nVenturebeat, Researchers turn to Harry Potter to make AI forget about copyrighted material, 2023.10.06.\n']","The main goals of the AI Safety Summit on Nov 2, 2023, included discussing the safety of AI systems, addressing the potential risks associated with AI, and promoting the responsible development and deployment of AI technologies.",reasoning,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 17, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 17, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
What metrics gauge AGI's effectiveness vs. benchmarks and other AI?,"['�요\n∙ (범용성과 성능을 모두 평가) 진정한 AGI는 인간을 능가하는 폭넓은 범용성과 기술의 깊이를 모두 요구\n∙ (인지와 메타인지 작업에 중점) 물리적 작업의 수행 능력은 AGI의 필수 전제조건이 아니며, 인지 작업과\n메타인지 작업(예; 새로운 작업의 학습 능력, 인간에게 도움을 요청할 시점을 아는 능력)이 핵심\n∙ (실제 구현보다 잠재력에 집중) 통제된 상황에서 발휘되는 성능에 따라 AGI를 규정하고 테스트를 진행\n∙ (생태학적 타당도를 갖춘 벤치마크 사용) AGI에 대한 벤치마크는 사람들이 경제적· 사회적 또는 예술적으로\n가치 있게 여기는 실질적인 작업을 대상으로 성능 평가 필요\n∙ (종점이 아닌 AGI를 향한 경로에 중점) 단계별 접근방식을 통해 AGI의 발전 상태를 점진적으로 측정\nn 연구진은 상기 원칙에 따라 AI를 성능에 따라 0~5단계와 광범위한 목적에 활용될 수 있는 범용 AI 및 특정\n과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현', '구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표\nKEY Contents\nn 구글 딥마인드 연구진이 성능과 범용성, 자율성을 기준으로 범용 AI(AGI)의 수준을\n0~5단계까지 총 6단계로 구분한 프레임워크를 공개\nn 현재 AGI는 단백질 구조를 예측하는 알파폴드와 같은 특정 용도에서는 5단계 수준을 달성했지만\n광범위하게 활용될 수 있는 범용에서는 1단계 수준에 머물러 있음\n£챗GPT와 구글 바드와 같은 AI 챗봇은 범용 AI 1단계 수준\nn 구글 딥마인드 연구진은 2023년 11월 4일 범용 AI(Artificial General Intelligence, AGI) 모델을 용도와\n성능에 따라 분류하는 프레임워크를 제시한 논문을 발표\n∙ 프레임워크의 목적은 AGI의 성능, 범용성, 자율성 수준을 정의하여 모델 간 비교와 위험 평가, AGI\n달성까지의 진행 상황을 측정할 수 있는 공통 기준을 제공하기 위함\nn 연구진은 AGI 개념 정의에 필요한 기준을 수립하기 위한 6가지 원칙을 아래와 같이 도출\n∙ (프로세스가 아닌 기능에 중점) AI가 어떻게 작동하는지보다 무엇을 할 수 있는지가 더 �']",The context does not provide specific metrics that gauge AGI's effectiveness compared to benchmarks and other AI.,multi_context,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
How does Cohere's Data Provenance Explorer boost data transparency amid integrity concerns?,"[' 법적 프레임\n워크의 필요성을 제기\n∙ 일례로 데이터를 수집한 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을\n적용해야 하는지 실무자의 판단이 어려울 수 있으며, 서로 다른 라이선스를 적용받는 개별 데이터셋을\n하나로 통합해 사용하는 경우에도 각각의 라이선스 조건 준수에 어려움이 발생\n☞ 출처 : Cohere, Data Provenance Explorer Launches to Tackle Data Transparency Crisis, 2023.10.25.\n8\n']",Cohere's Data Provenance Explorer boosts data transparency by addressing integrity concerns through the application of various techniques that enhance the reliability of data sources and their usage.,conditional,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 10, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
"What were the main AI governance outcomes from the Summit, focusing on ethics and regulations?","['SPRi AI Brief |\n2023-12월호\nG7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의\nKEY Contents\nn G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인\n채택을 권고하는 AI 국제 행동강령을 마련\nn 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와\n이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구\n£G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련\nn 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제\n행동강령(International Code of Conduct for Advanced AI Systems)에 합의\n∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과\n정보공유를 위해 ‘히로시마 AI 프로세스’를 출범**\n∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의\n위험 식별과 완화에 필요한 조치를 포함\n* 주요 7개국(G7)은 미국, 일본, 독일, 영', '1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언\nKEY Contents\nn 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을\n위한 협력 방안을 담은 블레츨리 선언을 발표\nn 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며,\n영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정\n£AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의\nn 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에\n참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표\n∙ 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이\n중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여\nAI 시스템의 안전을 보장할 책임이 있다고']","The main AI governance outcomes from the Summit included the establishment of an International Code of Conduct for Advanced AI Systems, which emphasizes ethical guidelines and regulations for AI development and deployment. The G7 countries agreed on principles to ensure that AI systems are developed responsibly, with a focus on safety, transparency, and accountability. Additionally, there was a commitment to enhance international cooperation in AI governance, addressing issues such as bias, privacy, and the societal impact of AI technologies.",conditional,"[{'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 4, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}, {'source': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 5, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': ""D:20231208132838+09'00'"", 'ModDate': ""D:20231208132838+09'00'"", 'PDFVersion': '1.4', 'filename': '/content/data/MyDrive/ai_lecture/3. Large Language Models/data/SPRI_AI_Brief_2023년12월호_F.pdf'}]",True
